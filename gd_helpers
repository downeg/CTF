#!/usr/bin/env python3

'''
Global variables and functions.

'''

#import gzip
import logging
from datetime import datetime as dt
from os import stat as stat

#Global vars
ACTIVE_TIER = "0x2"
DISKS = []
DD3300 = False
DDVE = False
DDVE_STRIPE_ZERO_COUNT = 0
MODEL = ""
NO_ERR = 'no_err'
STRIPES = []
RESYNC = False

#Datetime range.
MAX_DATE = dt.today()
MIN_DATE = "Jan 01 2023 00:00:00"
MIN_DATE = dt.strptime(MIN_DATE, '%b %d %Y %H:%M:%S')
MOST_RECENT_ASUP = MIN_DATE

#Logger defaults.
LOG_FORMAT =	"%(asctime)s  %(levelname)s %(message)s"
LOG_FILE = "dd_raid_rat.info"
LOG_LEVEL = "INFO"
screen_logger = None

#ASCII Colours for text output.
GREEN = "\033[1;32m"
RED = "\033[1;31m"
BLUE = "\033[1;34m"
YELLOW = "\033[1;33m"
RESET = "\033[1;0m"

#Error codes for stripe unit headers.
STRIPE_UNIT_ERRORS = {
    "1" : ["DD_DAG_HDR_ERR_MISSING","corresponding disk not exist"],
    "2" : ["DD_DAG_HDR_ERR_MAGIC","su header magic mismatch"],
    "4" : ["DD_DAG_HDR_ERR_ARR_ID","array id mismatch"],
    "8" : ["DD_DAG_HDR_ERR_DISK_IDX","disk index mismatch"],
    "10" : ["DD_DAG_HDR_ERR_SU_IDX","su index mismatch"],
    "20" : ["DD_DAG_HDR_ERR_NR_DISK","total number of disks mismatch"],
    "40" : ["DD_DAG_HDR_ERR_DCHKSUM","data checksum mismatch"],
    "80" : ["DD_DAG_HDR_ERR_HCHKSUM","header checksum mismatch"],
    "100" : ["DD_DAG_HDR_ERR_TIMESTMP","invalid timestamp value"],
    "200" : ["DD_DAG_HDR_ERR_STRIP_NR_1","stripe_nr > total nr of stripes in the array"],
    "400" : ["DD_DAG_HDR_ERR_STRIP_NR_2","stripe_nr != stripe_nr calculated from LBA (misplaced write)"],
    "800" : ["DD_DAG_HDR_ERR_OLD_TIMESTMP","this timestamp smaller than the rest of stripe (lost write)"]   ,
    "1000"  : ["DD_DAG_HDR_ERR_STRIP_NR_3","stripe_nr != the rest of the disk. (misplaced write)"],
    "X" : ["MISSING","disk missing"],
    "no_err" : ["No error","No error"]}

def setup_logging():
    ''' Setup the logging functionality.
    '''
    global screen_logger
    try:
        logging.basicConfig(filename=LOG_FILE, level=LOG_LEVEL, format=LOG_FORMAT)
    except:
        logging.basicConfig(filename="raid_rat.info", level=LOG_LEVEL, format=LOG_FORMAT)
    screen_logger = logging.getLogger(__name__)
    screen_logger.setLevel(LOG_LEVEL)
    screen_sh = logging.StreamHandler()
    screen_sh.setFormatter(logging.Formatter("%(asctime)s  %(levelname)s %(message)s"))
    screen_logger.addHandler(screen_sh)

def get_asup_date(line):
    ''' Create a datetime object from the GENERATED_ON= line of an ASUP.
    '''
    asup_date = line.strip()
    asup_date = asup_date.split("=")[1]
    tmp_date = asup_date.split()
    asup_date = tmp_date[1] + " " + tmp_date[2]\
        + " " + tmp_date[5] + " " + tmp_date[3]
    return dt.strptime(asup_date.strip(), '%b %d %Y %H:%M:%S')

def get_file_year(file):
    '''Returns the year of file's mtime to be used in a
       Stripe object's datetime as the year is not seen in 
       kern.info timestamp.
    '''
    return dt.fromtimestamp(stat(file).st_mtime).year

def tokenizer(line):
    '''Custom tokenizer for DD ASUP logs.
       Removes [] brackets and spaces and returns word list.
    '''
    return list(filter(lambda x: x != " " and x != "", line.replace("]","[").split("[")))

def open_file_stream(file):
    '''To be used for gzip checks
    '''
    try:
        stream = open(file, "rt", errors='replace')
    except FileNotFoundError as e:
        logging.critical(f"Could not open file: {file}")
        screen_logger.critical(f"{RED}Could not open file: {file}{RESET}")
        logging.critical(f"QUIT")
        exit()
    except OSError as e:
        print("TODO: Implement the gzip module", e)
        exit()
    return stream

def check_model(model):
    '''Sets flags for DDVE and Vulcan models.
    '''
    global DDVE, DD3300
    if model in ["DDVE", "DD VE","DD3300", "DP4400", "DD VE Version 4.0", 
                 "DD VE Version 5.0", "DD VE Version 6.0"]:
        DDVE = True
    if model in ["DD3300", "DP4400"]:
        DD3300 = True
    if model == "DD6400":
        screen_logger.critical(f"{model} is not supported.")
        exit()

def get_base_offset(offset):
    '''Calculates base offset for DDVE stripes
    '''
    offset = int(offset)
    base_offset = (offset // 4718592) * 4718592
    return str(base_offset)

def unique_stripe_list():
    ''' Return a unique list of stripes that need to be fixed.
        Only the most recent occurrance of a unique stripe is returned.
    '''
    unique = {}
    for s in STRIPES:
        if not s.completed:
            if MIN_DATE <= s.datetime and s.datetime <= MAX_DATE:
                if s.stripe in unique.keys():
                    if unique[s.stripe].datetime < s.datetime:
                        unique[s.stripe] = s
                else:
                    unique[s.stripe] = s
    return unique.values()

def get_completed_list():
    ''' Return a unique list of stripes that completed the fix.
        Only the most recent occurrance of a completed fix is returned.
    '''
    unique = {}
    for s in STRIPES:
        if s.completed:
            if s.stripe in unique.keys():
                if unique[s.stripe].datetime < s.datetime:
                    unique[s.stripe] = s
            else:
                unique[s.stripe] = s
    return unique.values()

def match_array_id():
    ''' Match the aray_id to the ppart number for each stripe.
        Add the array_id to the stripe object.
    '''
    for s in STRIPES:
        for d in DISKS:
            if (d.ppart == s.ppart and d.dg == s.dg):
                s.add_array_id(d.array_id)
                break

def change_datetime():
    ''' Set the MAX_TIME and MIN_TIME used for searches to 
        user defined datetime range.
    '''
    global MIN_DATE
    global MAX_DATE
    min = str(input(f"{GREEN}Enter start date/time in format Jan 01 2000 00:00:00: {RESET}"))
    if min != "":
        try:
            MIN_DATE = dt.strptime(min, '%b %d %Y %H:%M:%S')
        except Exception as e:
            logging.exception(f"Date formatting exception: {min}")
            screen_logger.critical(f"{RED}Not a valid date format: {min}{RESET}")
            logging.critical(f"QUIT")
            exit()           
    max = str(input(f"{GREEN}Enter end date/time in format Jan 01 2000 00:00:00: {RESET}"))
    if max != "":
        try:
            MAX_DATE = dt.strptime(max, '%b %d %Y %H:%M:%S')
        except Exception as e:
            logging.exception(f"Date formatting exception: {max}")
            screen_logger.critical(f"{RED}Not a valid date format: {max}{RESET}")
            logging.critical(f"QUIT")
            exit()    
    print(f"{GREEN}Time range set: {MIN_DATE.strftime('%b %d %H:%M:%S')} to "
          f"{MAX_DATE.strftime('%b %d %H:%M:%S')}{RESET}")
    if MAX_DATE < MIN_DATE:
        error = (f"Start time {MIN_DATE.strftime('%b %d %H:%M:%S')} cannot be "
                 f"before end time: {MAX_DATE.strftime('%b %d %H:%M:%S')}")
        screen_logger.critical(f"{RED}{error}{RESET}")
        logging.critical(f"{error}")
        logging.critical(f"QUIT")
        exit()

def save_inflight_stripes():
    ''' Save the stripe list to a file in the format used by
        dd_raid_rescue command.
    '''
    try:
        out_file = f"physical_stripes_{dt.today().strftime('%s')}"
        out_file_handle = open(out_file, "w")
        unique = unique_stripe_list()
        for s in unique:
            out_file_handle.write(f"{s.stripe}\n")
        out_file_handle.close
        print(f"{GREEN}Unique stripe list written to {out_file}{RESET}")
    except Exception as e:
        screen_logger.critical(f"{RED}Could not write stripes to file.{RESET}")
        logging.exception(f"{RED}Could not write stripes to file. {e}{RESET}")

if __name__ == "__main__":
    print("This is the global vars and helper functions module.")
